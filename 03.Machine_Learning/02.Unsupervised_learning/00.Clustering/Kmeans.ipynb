{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms belonging to the family of Unsupervised Learning have no variable to predict tied to the data. Instead of having an output, the data only has an input which would be multiple variables that describe the data. This is where clustering comes in.\n",
    "**K-Means** is a very popular clustering technique.K-Means falls under the category of **centroid-based clustering**. A centroid is a data point (imaginary or real) at the center of a cluster. In centroid-based clustering, clusters are represented by a central vector or a centroid. This centroid might not necessarily be a member of the dataset. Centroid-based clustering is an iterative algorithm in which the notion of similarity is derived by how close a data point is to the centroid of the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it works?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you will need a sample dataset (training set):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Objects | X    | Y    | Z    |\n",
    "|---------|------|------|------|\n",
    "|  OB-1   | 1    |   4  |   1  |\n",
    "|  OB-2   | 1    |   2  |   2  |\n",
    "|  OB-3   | 1    |   4  |   2  |\n",
    "|  OB-4   | 2    |   1  |   2  |\n",
    "|  OB-5   | 1    |   1  |   1  |\n",
    "|  OB-6   | 2    |   4  |   2  |\n",
    "|  OB-7   | 1    |   1  |   2  |\n",
    "|  OB-8   | 2    |   1  |   1  |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample dataset contains 8 objects with their X, Y and Z coordinates. Your task is to cluster these objects into two clusters (here you define the value of K (of K-Means) in essence to be 2).\n",
    "\n",
    "So, the algorithm works by:\n",
    "\n",
    "- Taking any two centroids or data points (as you took 2 as K hence the number of centroids also 2) in its account initially.\n",
    "\n",
    "\n",
    "- After choosing the centroids, (say C1 and C2) the data points (coordinates here) are assigned to any of the Clusters (letâ€™s take centroids = clusters for the time being) depending upon the distance between them and the centroids.\n",
    "\n",
    "\n",
    "- Assume that the algorithm chose OB-2 (1,2,2) and OB-6 (2,4,2) as centroids and cluster 1 and cluster 2 as well.\n",
    "\n",
    "\n",
    "- For measuring the distances, you take the following distance measurement function (also termed as similarity measurement function):\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ d = \\lvert{x2-x1} + \\lvert{y2-y1}\\rvert + \\lvert{z2-z1}\\rvert$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also known as the **Taxicab distance or Manhattan distance**, where d is distance measurement between two objects, (x1,y1,z1) and (x2,y2,z2) are the X, Y and Z coordinates of any two objects taken for distance measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows the calculation of distances (using the above distance measurement function) between the objects and centroids (OB-2 and OB-6):\n",
    "\n",
    "| Objects | X    | Y    | Z    | Distance from C1(1,2,2)    | Distance from C2(2,4,2)   |\n",
    "|---------|------|------|------|----------------------------|---------------------------|\n",
    "|  OB-1   | 1    |   4  |   1  |      3                     |      2                    |\n",
    "|  OB-2   | 1    |   2  |   2  |      0                     |      3                    |\n",
    "|  OB-3   | 1    |   4  |   2  |      2                     |      1                    |\n",
    "|  OB-4   | 2    |   1  |   2  |      2                     |      3                    |\n",
    "|  OB-5   | 1    |   1  |   1  |      2                     |      5                    |\n",
    "|  OB-6   | 2    |   4  |   2  |      3                     |      0                    |\n",
    "|  OB-7   | 1    |   1  |   2  |      1                     |      4                    |\n",
    "|  OB-8   | 2    |   1  |   1  |      3                     |      4                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objects are clustered based on their distances between the centroids. An object which has a shorter distance between a centroid (say C1) than the other centroid (say C2) will fall into the cluster of C1. After the initial pass of clustering, the clustered objects will look something like the following:\n",
    "\n",
    "| Cluster 1 | \n",
    "|-----------|\n",
    "|  OB-2     |  \n",
    "|  OB-4     | \n",
    "|  OB-5     |  \n",
    "|  OB-7     | \n",
    "|  OB-8     | \n",
    "\n",
    "| Cluster 2 | \n",
    "|-----------|\n",
    "|  OB-1     |  \n",
    "|  OB-3     | \n",
    "|  OB-6     |  \n",
    "\n",
    "Now the algorithm will continue updating cluster centroids (i.e the coordinates) until they cannot be updated anymore (more on when it cannot be updated later). The updation takes place in the following manner:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/updation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, following this rule the updated cluster 1 will be ((1+2+1+1+2)/5, (2+1+1+1+1)/5,(2+2+1+2+1)/5) = (1.4,1.2,1.6). And for cluster 2 it will be ((1+1+2)/3, (4+4+4)/3, (1+2+2)/3) = (1.33, 4, 1.66).\n",
    "\n",
    "After this, the algorithm again starts finding the distances between the data points and newly derived cluster centroids. So the new distances will be like following:\n",
    "\n",
    "| Objects | X    | Y    | Z    | Distance from C1(1.4,1.2,1.6)    | Distance from C2(1.33,4,1.66)   |\n",
    "|---------|------|------|------|----------------------------------|---------------------------------|\n",
    "|  OB-1   | 1    |   4  |   1  |            3.8                   |            1                    |\n",
    "|  OB-2   | 1    |   2  |   2  |            1.6                   |            2.66                 |\n",
    "|  OB-3   | 1    |   4  |   2  |            3.6                   |            0.66                 |\n",
    "|  OB-4   | 2    |   1  |   2  |            1.2                   |            4                    |\n",
    "|  OB-5   | 1    |   1  |   1  |            1.2                   |            4                    |\n",
    "|  OB-6   | 2    |   4  |   2  |            3.8                   |            1                    |\n",
    "|  OB-7   | 1    |   1  |   2  |            1                     |            3.66                 |\n",
    "|  OB-8   | 2    |   1  |   1  |            1.4                   |            4.33                 |\n",
    "\n",
    "\n",
    "The new assignments of the objects with respect to the updated clusters will be:\n",
    "\n",
    "| Cluster 1 | \n",
    "|-----------|\n",
    "|  OB-2     |  \n",
    "|  OB-4     | \n",
    "|  OB-5     |  \n",
    "|  OB-7     | \n",
    "|  OB-8     | \n",
    "\n",
    "| Cluster 2 | \n",
    "|-----------|\n",
    "|  OB-1     |  \n",
    "|  OB-3     | \n",
    "|  OB-6     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the algorithm no longer updates the centroids. Because there is no change in the current cluster formation, it is the same as the previous formation.\n",
    "Now when, you are done with the cluster formation with K-Means you may apply it to some data the algorithm has not seen before (what you call a Test set). Let's generate that:\n",
    "\n",
    "| Objects | X    | Y    | Z    |\n",
    "|---------|------|------|------|\n",
    "|  OB-1   | 2    |   4  |   1  |\n",
    "|  OB-2   | 2    |   2  |   2  |\n",
    "|  OB-3   | 1    |   2  |   1  |\n",
    "|  OB-4   | 2    |   2  |   1  |\n",
    "\n",
    "\n",
    "After applying K-means on the above dataset, the final clusters will be:\n",
    "\n",
    "| Cluster 1 | \n",
    "|-----------|\n",
    "|  OB-2     |  \n",
    "|  OB-3     | \n",
    "|  OB-4     |  \n",
    " \n",
    "\n",
    "| Cluster 2 | \n",
    "|-----------|\n",
    "|  OB-1     |  \n",
    "\n",
    "\n",
    "Any application of an algorithm is incomplete if one is not sure about its performance. Now, in order to know how well the K-Means algorithm is performing there are certain metrics to consider. Some of these metrics are:\n",
    "\n",
    " - Adjusted rand index\n",
    " \n",
    " \n",
    "- Mutual information based scoring\n",
    "\n",
    "\n",
    "- Homogeneity, completeness and v-measure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building in Scikit-learn\n",
    "\n",
    "For the implementation part, you will be using the Titanic dataset (available [here](https://www.kaggle.com/c/titanic). Before proceeding with it, I would like to discuss some facts about the data itself. The sinking of the RMS Titanic is one of the most infamous shipwrecks in history. On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "Now, talking about the dataset, the training set contains several records about the passengers of Titanic (hence the name of the dataset). It has 12 features capturing information about passenger_class, port_of_Embarkation, passenger_fare etc. The dataset's label is survival which denotes the survivial status of a particular passenger. Your task is to cluster the records into two i.e. the ones who survived and the ones who did not.\n",
    "\n",
    "You might be thinking that since it is a labeled dataset, how could it be used for a clustering task? You just have to drop the 'survival' column from the dataset and make it unlabeled. It's the task of K-Means to cluster the records of the datasets if they survived or not.\n",
    "\n",
    "For this tutorial, you will need the following Python packages: pandas, NumPy, scikit-learn, Seaborn and Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train and test datasets to create two DataFrames\n",
    "\n",
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "test = pd.read_csv(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's preview the kind of data you will be working with by printing some samples from both the train and test DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Train_Set *****\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "\n",
      "***** Test_Set *****\n",
      "   PassengerId  Pclass                                          Name     Sex  \\\n",
      "0          892       3                              Kelly, Mr. James    male   \n",
      "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
      "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
      "3          895       3                              Wirz, Mr. Albert    male   \n",
      "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
      "\n",
      "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
      "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
      "1  47.0      1      0   363272   7.0000   NaN        S  \n",
      "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
      "3  27.0      0      0   315154   8.6625   NaN        S  \n",
      "4  22.0      1      1  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "print(\"***** Train_Set *****\")\n",
    "print(train.head())\n",
    "print(\"\\n\")\n",
    "print(\"***** Test_Set *****\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get some initial statistics of both the train and test DataFrames using pandas' **describe()** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Train_Set *****\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "\n",
      "\n",
      "***** Test_Set *****\n",
      "       PassengerId      Pclass         Age       SibSp       Parch        Fare\n",
      "count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n",
      "mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n",
      "std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n",
      "min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n",
      "25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n",
      "50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n",
      "75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n",
      "max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n"
     ]
    }
   ],
   "source": [
    "print(\"***** Train_Set *****\")\n",
    "print(train.describe())\n",
    "print(\"\\n\")\n",
    "print(\"***** Test_Set *****\")\n",
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, from the above outputs you definitely got to know about the features of the dataset and some basic statistics of it. I will list the feature names for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId' 'Survived' 'Pclass' 'Name' 'Sex' 'Age' 'SibSp' 'Parch'\n",
      " 'Ticket' 'Fare' 'Cabin' 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "print(train.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to note that not all machine learning algorithms support missing values in the data that you are feeding to them. K-Means being one of them. So we need to handle the missing values present in the data. Let's first see where are the values missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass   Name    Sex    Age  SibSp  Parch  Ticket  \\\n",
       "0        False     False   False  False  False  False  False  False   False   \n",
       "1        False     False   False  False  False  False  False  False   False   \n",
       "2        False     False   False  False  False  False  False  False   False   \n",
       "3        False     False   False  False  False  False  False  False   False   \n",
       "4        False     False   False  False  False  False  False  False   False   \n",
       "\n",
       "    Fare  Cabin  Embarked  \n",
       "0  False   True     False  \n",
       "1  False  False     False  \n",
       "2  False   True     False  \n",
       "3  False  False     False  \n",
       "4  False   True     False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the train set\n",
    "train.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass   Name    Sex    Age  SibSp  Parch  Ticket   Fare  \\\n",
       "0        False   False  False  False  False  False  False   False  False   \n",
       "1        False   False  False  False  False  False  False   False  False   \n",
       "2        False   False  False  False  False  False  False   False  False   \n",
       "3        False   False  False  False  False  False  False   False  False   \n",
       "4        False   False  False  False  False  False  False   False  False   \n",
       "\n",
       "   Cabin  Embarked  \n",
       "0   True     False  \n",
       "1   True     False  \n",
       "2   True     False  \n",
       "3   True     False  \n",
       "4   True     False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the test set\n",
    "test.isna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the total number of missing values in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****In the train set*****\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "*****In the test set*****\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"*****In the train set*****\")\n",
    "print(train.isna().sum())\n",
    "print(\"\\n\")\n",
    "print(\"*****In the test set*****\")\n",
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, you can see in the training set, in the columns Age, Cabin and Embarked, there are missing values and in the test set, the Age and Cabin columns contain missing values.\n",
    "\n",
    "There are a couple of ways to handle missing values:\n",
    "\n",
    " - Remove rows with missing values\n",
    "- Impute missing values\n",
    "\n",
    "\n",
    "I,personally, prefer the latter one because if you remove the rows with missing values it can cause insufficiency in the data which in turn results in inefficient training of the machine learning model.\n",
    "\n",
    "Now, there are several ways you can perform the **imputation**:\n",
    "\n",
    "- A constant value that has meaning within the domain, such as 0, distinct from all other values.\n",
    "- A value from another randomly selected record.\n",
    "- A mean, median or mode value for the column.\n",
    "- A value estimated by another machine learning model.\n",
    "\n",
    "\n",
    "Any imputation performed on the train set will have to be performed on test data in the future when predictions are needed from the final machine learning model. This needs to be taken into consideration when choosing how to impute the missing values.\n",
    "\n",
    "Pandas provides the **fillna()** function for replacing missing values with a specific value. Let's apply that with Mean Imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mean column values in the train set\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "\n",
    "# Fill missing values with mean column values in the test set\n",
    "test.fillna(test.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have imputed the missing values in the dataset, it's time to see if the dataset still has any missing values.\n",
    "\n",
    "For the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if you have any missing values in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, you can see there are still some missing values in the Cabin and Embarked columns. This is because these values are non-numeric. In order to perform the imputation the values need to be in numeric form. There are ways to convert a non-numeric value to a numeric one. More on this later.\n",
    "\n",
    "Let's do some more analytics in order to understand the data better. Understanding is really required in order to perform any Machine Learning task. Let's start with finding out which features are categorical and which are numerical.\n",
    "\n",
    "1. Categorical: Survived, Sex, and Embarked. Ordinal: Pclass.\n",
    "2. Continuous: Age, Fare. Discrete: SibSp, Parch.\n",
    "\n",
    "\n",
    "Two features are left out which are not listed above in any of the categories. Yes, you guessed it right, **Ticket** and **Cabin**. Ticket is a mix of numeric and alphanumeric data types. Cabin is alphanumeric. Let see some sample values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           A/5 21171\n",
       "1            PC 17599\n",
       "2    STON/O2. 3101282\n",
       "3              113803\n",
       "4              373450\n",
       "Name: Ticket, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Ticket'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     NaN\n",
       "1     C85\n",
       "2     NaN\n",
       "3    C123\n",
       "4     NaN\n",
       "Name: Cabin, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Cabin'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the survival count of passengers with respect to the following features:\n",
    "\n",
    "- Pclass\n",
    "- Sex\n",
    "- SibSp\n",
    "- Parch\n",
    "\n",
    "\n",
    "Let's do that one by one:\n",
    "\n",
    "Survival count with respect to Pclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survival count with respect to Sex:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the survival rate of female passengers is significantly higher for males.\n",
    "\n",
    "Survival count with respect to SibSp:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.535885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.345395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Survived\n",
       "1      1  0.535885\n",
       "2      2  0.464286\n",
       "0      0  0.345395\n",
       "3      3  0.250000\n",
       "4      4  0.166667\n",
       "5      5  0.000000\n",
       "6      8  0.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for some quick plotting. Let's first plot the graph of \"Age vs. Survived\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2ec33875c48>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = sns.FacetGrid(train, col='Survived')\n",
    "g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its time to see how the Pclass and Survived features are related to eachother with a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 514.88x475.2 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = sns.FacetGrid(train, col='Survived', row='Pclass', height=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enough of visualization and analytics for now! Let's actually build a K-Means model with the training set. But before that you will need some data preprocessing as well. You can see that not all the feature values are of same type. Some of them are numerical and some of them are not. In order to ease the computation, you will feed all numerical data to the model. Let's see the data types of different features that you have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, you can see that the following features are non-numeric:\n",
    "\n",
    "- Name\n",
    "- Sex\n",
    "- Ticket\n",
    "- Cabin\n",
    "- Embarked\n",
    "\n",
    "\n",
    "Before converting them into numeric ones, you might want to do some feature engineering, i.e. features like Name, Ticket, Cabin and Embarked do not have any impact on the survival status of the passengers. Often, it is better to train your model with only significant features than to train it with all the features, including unnecessary ones. It not only helps in efficient modelling, but also the training of the model can happen in much lesser time. Although, feature engineering is a whole field of study itself, I will encourage you to dig it further. But for this tutorial, know that the features Name, Ticket, Cabin and Embarked can be dropped and they will not have significant impact on the training of the K-Means model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)\n",
    "test = test.drop(['Name','Ticket', 'Cabin','Embarked'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dropping part is done let's convert the 'Sex' feature to a numerical one (only 'Sex' is remaining now which is a non-numeric feature). You will do this using a technique called [Label Encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(train['Sex'])\n",
    "labelEncoder.fit(test['Sex'])\n",
    "train['Sex'] = labelEncoder.transform(train['Sex'])\n",
    "test['Sex'] = labelEncoder.transform(test['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Sex            891 non-null int32\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "dtypes: float64(2), int32(1), int64(5)\n",
      "memory usage: 52.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Let's investigate if you have non-numeric data left\n",
    "\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that the test set does not have the Survived feature.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 7 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Sex            418 non-null int32\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Fare           418 non-null float64\n",
      "dtypes: float64(2), int32(1), int64(4)\n",
      "memory usage: 21.4 KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brilliant!**\n",
    "Looks like you are good to go to train your K-Means model now.\n",
    "\n",
    "You can first drop the Survival column from the data with the drop() function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train.drop(['Survived'], 1).astype(float))\n",
    "y = np.array(train['Survived'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can review all the features you are going to feed to the algorithm with train.info().\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Sex            891 non-null int32\n",
      "Age            891 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Fare           891 non-null float64\n",
      "dtypes: float64(2), int32(1), int64(5)\n",
      "memory usage: 52.3 KB\n"
     ]
    }
   ],
   "source": [
    " train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now build the K-Means model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=2) # You want cluster the passenger records into 2: Survived or Not survived\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see all the other parameters of the model other than n_clusters. Let's see how well the model is doing by looking at the percentage of passenger records that were clustered correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49158249158249157\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = kmeans.predict(predict_me)\n",
    "    if prediction[0] == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is nice for the first go. Your model was able to cluster correctly with a 50% (accuracy of your model). But in order to enhance the performance of the model you could tweak some parameters of the model itself. I will list some of these parameters which the scikit-learn implementation of K-Means provides:\n",
    "\n",
    "1. algorithm\n",
    "2. max_iter\n",
    "3. n_jobs\n",
    "\n",
    "Let's tweak the values of these parameters and see if there is a change in the result.\n",
    "\n",
    "In [here](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), you will find a solid information about these parameters which you should dig further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you see a decrease in the score one of the reasons being you have not scaled the values of the different features that you are feeding to the model. The features in the dataset contain different ranges of values. So, what happens is a small change in a feature does not affect the other feature. So, it is also important to scale the values of the features to a same range.\n",
    "\n",
    "Let's do that now and for this experiment you are going to take 0 - 1 as the uniform value range across all the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=600,\n",
       "       n_clusters=2, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans.fit(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6262626262626263\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = kmeans.predict(predict_me)\n",
    "    if prediction[0] == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extra tip**:A function to compute the centroid of a cluster. The centroid is simply the mean of all of the examples currently assigned to the cluster. Can you make it work for the Titanic dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_centroids(X, idx, k):\n",
    "    m, n = X.shape\n",
    "    centroids = np.zeros((k, n))\n",
    "    \n",
    "    for i in range(k):\n",
    "        indices = np.where(idx == i)\n",
    "        centroids[i,:] = (np.sum(X[indices,:], axis=1) / len(indices[0])).ravel()\n",
    "    \n",
    "    return centroids\n",
    "\n",
    "compute_centroids(X, idx, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great!**\n",
    "\n",
    "So far you were able to load your data, preprocess it accordingly, do a little bit of feature engineering and finally you were able to make a K-Means model and see it in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons\n",
    "Now that you have a fairly good idea on how K-Means algorithm works let's discuss some its disadvantages.\n",
    "\n",
    "The biggest disadvantage is that K-Means requires you to pre-specify the number of clusters (k). However, for the Titanic dataset, you had some domain knowledge available that told you the number of people who survived in the shipwreck. This might not always be the case with real world datasets. Hierarchical clustering is an alternative approach that does not require a particular choice of clusters. An additional disadvantage of k-means is that it is sensitive to outliers and different results can occur if you change the ordering of the data.\n",
    "\n",
    "K-Means is a lazy learner where generalization of the training data is delayed until a query is made to the system. This means K-Means starts working only when you trigger it to, thus lazy learning methods can construct a different approximation or result to the target function for each encountered query. It is a good method for online learning, but it requires a possibly large amount of memory to store the data, and each request involves starting the identification of a local model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful links:\n",
    "    - https://arxiv.org/ftp/arxiv/papers/1405/1405.7471.pdf\n",
    "    - https://realpython.com/k-means-clustering-python/\n",
    "    - https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
