{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural networks** are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns. They interpret sensory data through a kind of machine perception, labeling or clustering raw input. The patterns they recognize are numerical, contained in vectors, into which all real-world data, be it images, sound, text or time series, must be translated.\n",
    "\n",
    "Neural networks help us cluster and classify. You can think of them as a clustering and classification layer on top of the data you store and manage. They help to group unlabeled data according to similarities among the example inputs, and they classify data when they have a labeled dataset to train on. (Neural networks can also extract features that are fed to other algorithms for clustering and classification; so you can think of deep neural networks as components of larger machine-learning applications involving algorithms for reinforcement learning, classification and regression.)\n",
    "\n",
    "\n",
    "The **Convolutional Neural Network (CNN)** architecture is central to deep learning, and it is what makes possible a range of applications for computer vision, from analyzing security footage and medical imaging to enabling the automation of vehicles and machines for industry and agriculture.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Convolutional means?\n",
    "\n",
    "CNN are named like that because of the operation they performed. Let’s understand the convolution operation using two matrices, a and b, of 1 dimension.\n",
    "\n",
    "a = [5,3,7,5,9,7]\n",
    "\n",
    "b = [1,2,3]\n",
    "\n",
    "In convolution operation, the arrays are multiplied element-wise, and the product is summed to create a new array, which represents a*b.\n",
    "\n",
    "The first three elements of the matrix a are multiplied with the elements of matrix b. The product is summed to get the result.\n",
    "\n",
    "![](assets/operation1.jpg)\n",
    "\n",
    "The next three elements from the matrix a are multiplied by the elements in matrix b, and the product is summed up.\n",
    "\n",
    "![](assets/operation2.jpg)\n",
    "\n",
    "This process continues until the convolution operation is complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A convolutional neural network is a [feed-forward neural network](https://brilliant.org/wiki/feedforward-neural-networks/) that is generally used to analyze visual images by processing data with grid-like topology. It’s also known as a ConvNet. A convolutional neural network is used to detect and classify objects in an image.\n",
    "\n",
    "Below is a neural network that identifies two types of flowers: Orchid and Rose.\n",
    "\n",
    "![](assets/cnn1.jpg)\n",
    "\n",
    "In CNN, every image is represented in the form of an array of pixel values.\n",
    "\n",
    "![](assets/cnn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CNN is the foundation of most computer vision technologies. Unlike traditional [multilayer perceptron](https://missinglink.ai/guides/neural-network-concepts/perceptrons-and-multi-layer-perceptrons-the-artificial-neuron-at-the-core-of-deep-learning/) architectures, it uses two operations called ‘convolution’ and pooling’ to reduce an image into its essential features, and uses those features to understand and classify the image.\n",
    "\n",
    "The *basic building blocks* of CNN are:\n",
    "\n",
    "   1. **Convolution layer** ━a “filter”, sometimes called a “kernel”, is passed over the image, viewing a few pixels at a time (for example, 3X3 or 5X5). The convolution operation is a dot product of the original pixel values with weights defined in the filter. The results are summed up into one number that represents all the pixels the filter observed\n",
    "   Consider the following 5x5 image whose pixel values are either 0 or 1. There’s also a filter matrix with a dimension of 3x3. Slide the filter matrix over the image and compute the dot product to get the convolved feature matrix.\n",
    "   ![](assets/conv_layer.jpg)\n",
    "    \n",
    "    \n",
    "   2. **Activation layer**━the convolution layer generates a matrix that is much smaller in size than the original image. This matrix is run through an activation layer, which introduces non-linearity to allow the network to train itself via backpropagation. The activation function is typically ReLu. ReLU stands for the rectified linear unit. Once the feature maps are extracted, the next step is to move them to a ReLU layer. ReLU performs an element-wise operation and sets all the negative pixels to 0. It introduces non-linearity to the network, and the generated output is a rectified feature map. Below is the graph of a ReLU function:\n",
    "   ![](assets/relu.jpg)\n",
    "   \n",
    "   The original image is scanned with multiple convolutions and ReLU layers for locating the features.\n",
    "   \n",
    "   ![](assets/Input_feature_map.gif)\n",
    "   \n",
    "   ![](assets/Input_feature_map1.gif)\n",
    "    \n",
    "    \n",
    "   3. **Pooling layer**━“pooling” is the process of further downsampling and reducing the size of the matrix. A filter is passed over the results of the previous layer and selects one number out of each group of values (typically the maximum, this is called max pooling). This allows the network to train much faster, focusing on the most important information in each feature of the image.\n",
    "    ![](assets/pooling.jpg)\n",
    "    \n",
    "   The pooling layer uses various filters to identify different parts of the image like edges, corners, body, feathers, eyes, and beak.\n",
    "   ![](assets/pooling1.jpg)\n",
    "   \n",
    "   Here’s how the structure of the convolution neural network looks so far:\n",
    "   \n",
    "![](assets/cnn2.jpg)\n",
    "\n",
    "\n",
    "Then, depending on the data, the next step in the process is called **flattening**. Flattening is used to convert all the resultant 2-Dimensional arrays from pooled feature maps into a single long continuous linear vector. The flattened matrix is fed as input to the fully connected layer to classify the image.\n",
    "\n",
    "\n",
    "![](assets/flattening.jpg)\n",
    "\n",
    "\n",
    "    \n",
    "   4. **Fully connected laye**r━a traditional multilayer perceptron structure. Its input is a one-dimensional vector representing the output of the previous layers. Its output is a list of probabilities for different possible labels attached to the image (e.g. dog, cat, bird). The label that receives the highest probability is the classification decision.\n",
    "    \n",
    "    \n",
    " ![](assets/cnn_final.jpg)\n",
    " \n",
    "There may be multiple activation and pooling layers, depending on the CNN architecture.\n",
    "\n",
    "\n",
    "![](assets/architecture_cnn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Applications\n",
    "\n",
    "People are doing cool things with CNN. Here are some common applications of computer vision powered by Convolutional Neural Networks:\n",
    "\n",
    " - Agriculture━farmers use hyperspectral or multispectral sensors to take pictures of crops, and analyze the images with computer vision to determine their health, or the viability of seeds to be sown.\n",
    " \n",
    " \n",
    " - Self-driving cars━CNNs are used for object detection and classification, performed in real time against live video footage from car cameras. Today’s self-driving cars are able to identify other vehicles, people and obstacles and navigate around them with surprising accuracy.\n",
    " \n",
    " \n",
    " - Surveillance━modern security systems with computer vision capabilities can identify crime, violence or theft in video footage in real time and alert security personnel. Again this leverages CNN-based object detection and classification in video frames.\n",
    " \n",
    " \n",
    "- Healthcare━computer vision in healthcare (click to read our extensive guide on the subject) helps diagnose diseases like pneumonia, diabetes and breast cancer. In many cases CNN-based analysis and diagnosis of medical images can be as accurate or even more accurate than a human technician or physician."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a CNN in Keras\n",
    "\n",
    "### Data\n",
    "\n",
    "Download the dataset [MNIST](https://www.tensorflow.org/datasets/catalog/mnist) and split it to training and testing set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model\n",
    "\n",
    "We’ll use the Sequential() function which is probably the easiest way to define a deep learning model in Keras. It lets you add layers on one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Keras [Conv2D](https://keras.io/api/layers/convolution_layers/convolution2d/) function to create a 2-dimensional convolutional layer, with kernel size (filter) of 5X5 pixels and a stride of 1 in x and y directions. The Conv2D command automatically creates the activation function for you━here we use ReLu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then use the [MaxPooling2D](https://keras.io/api/layers/pooling_layers/max_pooling2d/) function to add a 2D max pooling layer, with pooling filter sized 2X2 and stride of 2 in x and y directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add one more convolution and pooling layers━this time the convolution has 64 filters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, flatten the output and define the fully connected layers that generate probabilities for the ten prediction labels (0.9, the possible values of every written digit):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and training the CNN\n",
    "\n",
    "Compile the network using the model.compile() command. Select cross entropy loss function, Adam optimizer with learning rate 0.01, and accuracy as your metric to evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train it using model.fit(), passing the training and testing dataset, and specifying your batch size and number of epochs for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test),\n",
    "          callbacks=[history])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating performance\n",
    "\n",
    "Use the evaluate() function to evaluate the performance of the model, using accuracy as we defined previously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced CNN in TensorFlow\n",
    "\n",
    "This tutorial does the same thing as the previous one, processing MNIST dataset images and predicting which digit each represents. However, unlike the previous tutorial which used easy Keras command to run the network, here we create the network from its primitives directly in TensorFlow. This can help you understand how a CNN works behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data\n",
    "\n",
    "Input the MNIST dataset into TensorFlow and set basic parameters━learning rate, epochs and batch size (see our guide on hyperparameters  to learn more about these):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "learning_rate = 0.0001\n",
    "epochs = 10\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a placeholder for training data. MNIST images are 28X28 pixels, resulting in a 784-pixel flattened input. Reshape the input into a format appropriate to the CNN, and define a placeholder for the out━ten possible labels from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "x_shaped = tf.reshape(x, [-1, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution layer\n",
    "\n",
    "Create a function that defines a convolutional layer. In the function, we setup the input shape of the data, initialize weights and bias, create the convolutional layer using the tf.nn.conv2d function, and apply a ReLu activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_conv_layer(input_data, num_input_channels, num_filters, filter_shape, pool_shape, name):\n",
    "    conv_filt_shape = [filter_shape[0], filter_shape[1], num_input_channels,\n",
    "                      num_filters]\n",
    "    weights = tf.Variable(tf.truncated_normal(conv_filt_shape, stddev=0.03),\n",
    "                                      name=name+'_W')\n",
    "    bias = tf.Variable(tf.truncated_normal([num_filters]), name=name+'_b')\n",
    "    out_layer = tf.nn.conv2d(input_data, weights, [1, 1, 1, 1], padding='SAME')\n",
    "    out_layer += bias\n",
    "    out_layer = tf.nn.relu(out_layer)\n",
    "    ksize = [1, pool_shape[0], pool_shape[1], 1]\n",
    "    strides = [1, 2, 2, 1]\n",
    "    out_layer = tf.nn.max_pool(out_layer, ksize=ksize, strides=strides, \n",
    "                               padding='SAME')\n",
    "\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll use this function to create two convolutional layers, the first with 32 filters and the second with 64 filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = create_new_conv_layer(x_shaped, 1, 32, [5, 5], [2, 2], name='layer1')\n",
    "layer2 = create_new_conv_layer(layer1, 32, 64, [5, 5], [2, 2], name='layer2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully connected layers\n",
    "\n",
    "Flatten the output of the convolutional layers, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = tf.reshape(layer2, [-1, 7 * 7 * 64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup weights and biases, and create two densely connected layers, with softmax activation, which is appropriate for an output layer that generates probabilities for predictive labels. We’ll use a cross-entropy loss function, built into TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd1 = tf.Variable(tf.truncated_normal([7 * 7 * 64, 1000], stddev=0.03), name='wd1')\n",
    "bd1 = tf.Variable(tf.truncated_normal([1000], stddev=0.01), name='bd1')\n",
    "dense_layer1 = tf.matmul(flattened, wd1) + bd1\n",
    "dense_layer1 = tf.nn.relu(dense_layer1)\n",
    "wd2 = tf.Variable(tf.truncated_normal([1000, 10], stddev=0.03), name='wd2')\n",
    "bd2 = tf.Variable(tf.truncated_normal([10], stddev=0.01), name='bd2')\n",
    "dense_layer2 = tf.matmul(dense_layer1, wd2) + bd2\n",
    "y_ = tf.nn.softmax(dense_layer2)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=dense_layer2, labels=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network\n",
    "\n",
    "Define a parameter that can assess the accuracy of the network, initialize variables and train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "init_op = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    # initialise the variables\n",
    "    sess.run(init_op)\n",
    "    total_batch = int(len(mnist.train.labels) / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)\n",
    "            _, c = sess.run([optimiser, cross_entropy], \n",
    "                            feed_dict={x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        test_acc = sess.run(accuracy, \n",
    "                       feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "        print(\"Epoch:\", (epoch + 1), \"cost =\", \"{:.3f}\".format(avg_cost), \" \n",
    "                 test accuracy: {:.3f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Links:\n",
    "- https://hackernoon.com/building-a-feedforward-neural-network-from-scratch-in-python-d3526457156b\n",
    "- https://www.edureka.co/blog/convolutional-neural-network/\n",
    "- https://www.tensorflow.org/tutorials/images/cnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
